The use case diagram shows two roles: user(student) and Algorithm, and 3 use cases : upload image for recognition, preview result and save result. Algorithm is applied to two cases(upload image for recognition and preview result).
As the picture shown above, we have two business objects: Image, Text.  Image has some attributes such as filename and Text has text content which is converted by algorithm from Image.
It can be seen that the tool part includes four parts, Main, fileGenerator, importPics and concatenateImages. After setting parameters in main class, the fileGenerator class will create all the pictures with the parameters in class main, the pictures include pictures for all the English letters in ASCII table and numbers/punctuations. After generating the pictures, the main class will use importPics class method img_bw() to thresholding all the raw pictures created before and store them in different folders for later use. Lastly, the main class will generate random strings with words, numbers, and punctuation. Which will use the image generated before and concatenate them into one picture, this process will generate one label with TXT file and two different pictures, one with background and one without.
We use Flask which is a micro web framework written in Python to realize connecting the webpage and server.
Web Server Gateway Interface is a standard describing the specifications that concern communication between a client application and a web server. Our flask application has route() decorator to bind a function to the corresponding URL and javascript AJAX will send the request (image) and get the result (text) from the server.
Generally, the user initiates a request to our server through the browser, and this request goes back to access the view function. (If it does not involve a data call, then at this time the view function returns a template which is a web page to the user). In our project, we used a template which is an HTML page to render by flask.
The algorithm includes two main deep-learning models: the text detection model and the text recognition model.
The text detection model uses resnet-50 and FPN (Feature Pyramid Network) as a backbone to extract features and the head of the model uses the idea from DB-net, which can predict a probability map and a threshold map and use the threshold map to binarize the probability map and implement the instance segmentation of text line. The detection of each text line can be implemented by using a connected components' algorithm on the binary image. There is an RSN (Region Score Network) after the main detection model, which can give a probability of if there is a text line in the detection box to reduce the error detection result.
The text recognition model is a kind of optical character recognition model. The famous structure of the OCR model is using LSTM (Long short-term memory) or BiLSTM (Bi-directional Long Short-Term Memory), a kind of RNN to be the head of the model and chooses the CTC loss as the loss function. This kind of structure is mostly used for license plate identification, trademark recognition and speech recognition. Because of the structure, LSTM is suitable to extract feature from the data which has a sequence relationship. But each output of LSTM will be influenced by the data before it, the training difficulty will be grown by the length of the time step. And if the loss function is CTC loss, the training process will be a kind of weakly supervised training and the difficulty of training will become harder and harder.
So, our model uses a part of resnet-50 as a backbone, four residual modules to increase the receptive field and a 8x1 convolution to be the head to predict the type of characters.